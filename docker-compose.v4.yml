# V4 RTX-Enhanced Docker Compose Configuration
# Adds RTX AI Toolkit integration while maintaining V3 compatibility

version: '3.8'

services:
  # NEW: Docker Model Runner with RTX optimization
  model-runner:
    image: docker/model-runner:latest
    environment:
      - ENABLE_GPU=true
      - TCP_PORT=12434
      - HOST_ACCESS=true
      - RTX_OPTIMIZATION=enabled
    ports:
      - "12434:12434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - justnews-network

  # ENHANCED: Analyst with V4 hybrid architecture
  analyst:
    build:
      context: .
      dockerfile: agents/analyst/Dockerfile.v4  # New V4 Dockerfile
    depends_on:
      - model-runner
      - mcp_bus
      - db
    ports:
      - "8004:8004"
    networks:
      - justnews-network
    volumes:
      - ${HOME}/mistral_models:/app/models:ro
      - ./agents/analyst/models:/app/rtx_models:rw  # RTX model cache
    environment:
      # V4 Hybrid Configuration
      - INFERENCE_MODE=rtx_hybrid
      - RTX_PRIMARY_ENDPOINT=tensorrt://localhost:8080
      - DOCKER_FALLBACK_ENDPOINT=http://model-runner:12434/v1/
      - AIM_SDK_ENABLED=true
      
      # Model Configuration
      - PRIMARY_MODEL=mistral-7b-instruct-v0.3
      - FALLBACK_MODEL=ai/mistral:7b-instruct-v0.3
      - QUANTIZATION=int4
      
      # Performance Settings
      - RTX_BATCH_SIZE=4
      - RTX_MAX_TOKENS=512
      - PERFORMANCE_MONITORING=enabled
      - FEEDBACK_ENHANCED=true
      
      # Migration Settings
      - MIGRATION_PHASE=1
      - V3_FALLBACK_DISABLED=true  # Prevent crashes
      - RTX_MEMORY_MANAGEMENT=professional
      
      # Legacy Environment Variables (maintained for compatibility)
      - ANALYST_MODEL=mistralai/Mistral-7B-Instruct-v0.3
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
      - LOCAL_MODEL_PATH=/app/models/7B-Instruct-v0.3
      - ANALYST_FEEDBACK_LOG=./feedback_analyst.log
      - MCP_BUS_URL=http://mcp_bus:8000
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

networks:
  justnews-network:
    driver: bridge

# RTX AI Toolkit Integration Notes:
# 1. model-runner service provides Docker Model Runner with GPU optimization
# 2. analyst service enhanced with RTX hybrid configuration
# 3. V3 compatibility maintained through environment variables
# 4. Professional GPU memory management prevents crashes
# 5. Performance monitoring enabled for optimization tracking

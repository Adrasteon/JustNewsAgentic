nohup: ignoring input
INFO:analyst.hybrid_tools_v4:üìã V4 RTX Manager not available: attempted relative import with no known parent package
INFO:analyst.hybrid_tools_v4:üöÄ Initializing OPERATIONAL GPU-Accelerated Analyst
INFO:analyst.hybrid_tools_v4:‚úÖ GPU Available: NVIDIA GeForce RTX 3090
INFO:analyst.hybrid_tools_v4:‚úÖ GPU Memory: 23.5 GB
Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Device set to use cuda:0
/home/adra/miniconda3/envs/rapids-25.06/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.
  warnings.warn(
Device set to use cuda:0
INFO:analyst.hybrid_tools_v4:‚úÖ OPERATIONAL GPU models loaded (validated 42.1 articles/sec)
INFO:     Started server process [23282]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8004 (Press CTRL+C to quit)
üöÄ JustNews V4 Native GPU Analyst Service
==================================================
‚úÖ FastAPI GPU Analyst Service Ready
üåê Starting server on http://localhost:8004
üìã Endpoints:
  GET  /health - Health check
  GET  /performance/benchmark - Performance test
  POST /analyze/sentiment/batch - Batch sentiment analysis
  POST /analyze/bias/batch - Batch bias analysis
==================================================
INFO:     127.0.0.1:58870 - "GET /health HTTP/1.1" 200 OK
/home/adra/miniconda3/envs/rapids-25.06/lib/python3.12/site-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
INFO:analyst.hybrid_tools_v4:‚úÖ GPU batch sentiment: 3 articles in 0.219s (13.7 articles/sec)
/home/adra/miniconda3/envs/rapids-25.06/lib/python3.12/site-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
INFO:analyst.hybrid_tools_v4:‚úÖ GPU batch bias: 3 articles in 0.018s (166.3 articles/sec)
INFO:     127.0.0.1:49292 - "GET /performance/benchmark HTTP/1.1" 200 OK
INFO:     127.0.0.1:39372 - "GET /health HTTP/1.1" 200 OK
INFO:     127.0.0.1:50426 - "GET /health HTTP/1.1" 200 OK
INFO:analyst.hybrid_tools_v4:‚úÖ GPU batch sentiment: 3 articles in 0.036s (83.1 articles/sec)
INFO:     127.0.0.1:42072 - "POST /analyze/sentiment/batch HTTP/1.1" 200 OK
INFO:     127.0.0.1:42776 - "GET /health HTTP/1.1" 200 OK
INFO:     127.0.0.1:48264 - "GET /health HTTP/1.1" 200 OK
INFO:     127.0.0.1:53146 - "GET /health HTTP/1.1" 200 OK
INFO:     127.0.0.1:51698 - "GET /health HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [23282]
